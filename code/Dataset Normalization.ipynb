{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b32f9d32",
   "metadata": {},
   "source": [
    "# Dataset Normalization\n",
    "\n",
    "This file aims to obtain the normalization terms for the N-CMAPSS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "651f38e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dadf1d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fileloc(ds_no):\n",
    "    locations = {\n",
    "        1: '/data/courseac/N-CMAPSS/data_set/N-CMAPSS_DS01-005.h5',\n",
    "        2: '/data/courseac/N-CMAPSS/data_set/N-CMAPSS_DS02-006.h5',\n",
    "        3: '/data/courseac/N-CMAPSS/data_set/N-CMAPSS_DS03-012.h5',\n",
    "        4: '/data/courseac/N-CMAPSS/data_set/N-CMAPSS_DS04.h5',\n",
    "        5: '/data/courseac/N-CMAPSS/data_set/N-CMAPSS_DS05.h5',\n",
    "        6: '/data/courseac/N-CMAPSS/data_set/N-CMAPSS_DS06.h5',\n",
    "        7: '/data/courseac/N-CMAPSS/data_set/N-CMAPSS_DS07.h5',\n",
    "        8: '/data/courseac/N-CMAPSS/data_set/N-CMAPSS_DS08a-009.h5',\n",
    "        9: '/data/courseac/N-CMAPSS/data_set/N-CMAPSS_DS08c-008.h5',\n",
    "    }\n",
    "\n",
    "    return locations[ds_no]\n",
    "\n",
    "def load_data(fileloc):\n",
    "    with h5py.File(fileloc, 'r') as hdf:\n",
    "        # Development set\n",
    "        W_dev = np.array(hdf.get('W_dev'))             # W\n",
    "        X_s_dev = np.array(hdf.get('X_s_dev'))         # X_s\n",
    "        X_v_dev = np.array(hdf.get('X_v_dev'))         # X_v\n",
    "        T_dev = np.array(hdf.get('T_dev'))             # T\n",
    "        A_dev = np.array(hdf.get('A_dev'))             # Auxiliary\n",
    "\n",
    "    X_train = np.concatenate((W_dev, X_s_dev, X_v_dev, T_dev, A_dev), axis=1)\n",
    "\n",
    "    return X_train\n",
    "\n",
    "def save_normalization(ds_no):\n",
    "    fileloc = get_fileloc(ds_no)\n",
    "    \n",
    "    X_train = load_data(fileloc)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    dump(scaler, open('../scalers/scaler'+str(ds_no)+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bfcf44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [01:29<00:00,  9.91s/it]\n"
     ]
    }
   ],
   "source": [
    "for ds_no in tqdm(range(1,10)):\n",
    "    save_normalization(ds_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b63de2",
   "metadata": {},
   "source": [
    "## Get lengths of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76d79968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lengths():\n",
    "    lengths = []\n",
    "    for ds_no in tqdm(range(1,10)):\n",
    "        fileloc = get_fileloc(ds_no)\n",
    "        with h5py.File(fileloc, 'r') as hdf:\n",
    "            W_dev = np.array(hdf.get('W_dev'))\n",
    "            W_test = np.array(hdf.get('W_test'))\n",
    "            \n",
    "        lengths.append((len(W_dev), len(W_test)))\n",
    "        \n",
    "    return lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7afdd892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:05<00:00,  1.61it/s]\n"
     ]
    }
   ],
   "source": [
    "lengths = get_lengths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f2a28af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4906636, 2735232),\n",
       " (5263447, 1253743),\n",
       " (5571277, 4251560),\n",
       " (6377452, 3602561),\n",
       " (4350606, 2562046),\n",
       " (4257209, 2522447),\n",
       " (4350176, 2869786),\n",
       " (4885389, 3722997),\n",
       " (4299918, 2117819)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
