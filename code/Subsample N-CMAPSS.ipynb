{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e78f9b36",
   "metadata": {},
   "source": [
    "## Subsample N-CMAPSS Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cfda10",
   "metadata": {},
   "source": [
    "This file makes the N-CMAPSS dataset 1/10th of the size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a4b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "815203f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = '/data/courseac/N-CMAPSS/data_set/N-CMAPSS_DS01-005.h5'\n",
    "file2 = '/data/courseac/N-CMAPSS/data_set/N-CMAPSS_DS02-006.h5'\n",
    "file3 = '/data/courseac/N-CMAPSS/data_set/N-CMAPSS_DS03-012.h5'\n",
    "file4 = '/data/courseac/N-CMAPSS/data_set/N-CMAPSS_DS04.h5'\n",
    "file5 = '/data/courseac/N-CMAPSS/data_set/N-CMAPSS_DS05.h5'\n",
    "file6 = '/data/courseac/N-CMAPSS/data_set/N-CMAPSS_DS06.h5'\n",
    "file7 = '/data/courseac/N-CMAPSS/data_set/N-CMAPSS_DS07.h5'\n",
    "file8a = '/data/courseac/N-CMAPSS/data_set/N-CMAPSS_DS08a-009.h5'\n",
    "file8c = '/data/courseac/N-CMAPSS/data_set/N-CMAPSS_DS08c-008.h5'\n",
    "\n",
    "filenames = [file1, file2, file3, file4, file5, file6, file7, file8a, file8c]\n",
    "\n",
    "train_lengths = {\n",
    "    1: 4906636,\n",
    "    2: 5263447,\n",
    "    3: 5571277,\n",
    "    4: 6377452,\n",
    "    5: 4350606,\n",
    "    6: 4257209,\n",
    "    7: 4350176,\n",
    "    8: 4885389,\n",
    "    9: 4299918\n",
    "}\n",
    "\n",
    "test_lengths = {\n",
    "    1: 2735232,\n",
    "    2: 1253743,\n",
    "    3: 4251560,\n",
    "    4: 3602561,\n",
    "    5: 2562046,\n",
    "    6: 2522447,\n",
    "    7: 2869786,\n",
    "    8: 3722997,\n",
    "    9: 2117819\n",
    "}\n",
    "\n",
    "new_names = ['ds1', 'ds2', 'ds3', 'ds4', 'ds5', 'ds6', 'ds7', 'ds8a', 'ds8c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61f5407c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [02:13<00:00, 14.80s/it]\n"
     ]
    }
   ],
   "source": [
    "for i, filename in enumerate(tqdm(filenames)):\n",
    "    train_points = train_lengths[i+1]\n",
    "    test_points = test_lengths[i+1]\n",
    "    \n",
    "    train_indices = np.arange(0, train_points, 10)\n",
    "    test_indices = np.arange(0, test_points, 10)\n",
    "\n",
    "    with h5py.File(filename, 'r') as hdf:\n",
    "        W_dev = np.array(hdf.get('W_dev'))[train_indices]\n",
    "        X_s_dev = np.array(hdf.get('X_s_dev'))[train_indices]\n",
    "        X_v_dev = np.array(hdf.get('X_v_dev'))[train_indices]\n",
    "        T_dev = np.array(hdf.get('T_dev'))[train_indices]\n",
    "        Y_dev = np.array(hdf.get('Y_dev'))[train_indices]\n",
    "        A_dev = np.array(hdf.get('A_dev'))[train_indices]\n",
    "\n",
    "        X_train = np.concatenate((W_dev, X_s_dev, X_v_dev, T_dev, A_dev), axis=1)\n",
    "\n",
    "        W_test = np.array(hdf.get('W_test'))[test_indices]\n",
    "        X_s_test = np.array(hdf.get('X_s_test'))[test_indices]\n",
    "        X_v_test = np.array(hdf.get('X_v_test'))[test_indices]\n",
    "        T_test = np.array(hdf.get('T_test'))[test_indices]\n",
    "        Y_test = np.array(hdf.get('Y_test'))[test_indices]\n",
    "        A_test = np.array(hdf.get('A_test'))[test_indices]\n",
    "\n",
    "        X_test = np.concatenate((W_test, X_s_test, X_v_test, T_test, A_test), axis=1)\n",
    "        \n",
    "    new_file = h5py.File('/data/courseac/N-CMAPSS/subsampled/' + new_names[i] + '.h5', 'w')\n",
    "    subset_X_train = new_file.create_dataset('X_train', shape=(len(train_indices),46))\n",
    "    subset_X_train[:] = X_train\n",
    "\n",
    "    subset_y_train = new_file.create_dataset('y_train', shape=(len(train_indices),1))\n",
    "    subset_y_train[:] = Y_dev\n",
    "\n",
    "    subset_X_test = new_file.create_dataset('X_test', shape=(len(test_indices),46))\n",
    "    subset_X_test[:] = X_test\n",
    "\n",
    "    subset_y_test = new_file.create_dataset('y_test', shape=(len(test_indices),1))\n",
    "    subset_y_test[:] = Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca54ed2",
   "metadata": {},
   "source": [
    "## Testing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10a75bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(490664, 46)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('/data/courseac/N-CMAPSS/subsampled/ds1.h5', 'r') as hdf:\n",
    "    X_train = np.array(hdf.get('X_train'))\n",
    "    print(X_train.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
